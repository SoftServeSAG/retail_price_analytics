{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used: 12.752765655517578\n",
      "Modules load OK!\n"
     ]
    }
   ],
   "source": [
    "# load modules\n",
    "import gc\n",
    "from  psutil import virtual_memory\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pickle\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "\n",
    "def print_memory():\n",
    "    print('used:', virtual_memory().used / 1024. / 1024  / 1024)\n",
    "\n",
    "stop = stopwords.words('english') + list(string.punctuation) + ['rm', '[rm]']\n",
    "stop.remove('not')\n",
    "\n",
    "print_memory()\n",
    "print('Modules load OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def category_split(text):\n",
    "    if text == 'missing':\n",
    "        return (\"missing\", \"missing\", \"missing\")\n",
    "    else:\n",
    "        try:\n",
    "            text_split = text.split(\"/\")\n",
    "            return text_split\n",
    "        except:\n",
    "            print(text)\n",
    "            return (\"missing\", \"missing\", \"missing\")\n",
    "        \n",
    "negatives = {\n",
    "    \"didn't\": \"did_not\",\n",
    "    \"couldn't\": \"could_not\",\n",
    "    \"don't\": \"do_not\",\n",
    "    \"wouldn't\": \"would_not\",\n",
    "    \"doesn't\": \"does_not\",\n",
    "    \"wasn't\": \"was_not\",\n",
    "    \"weren't\": \"were_not\",\n",
    "    \"shouldn't\":\"should_not\",\n",
    "    \"isn't\": \"is_not\",\n",
    "    \"aren't\": \"are_not\",\n",
    "}\n",
    "\n",
    "regex = re.compile('[' +re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "\n",
    "def tokenize_text(text, treshold=2):\n",
    "    return [i for i in text.split(' ') if i not in stop and len(i) > treshold]\n",
    "    \n",
    "def len_text(text, treshold=2):\n",
    "    return len(tokenize_text(text, treshold))\n",
    "\n",
    "\n",
    "def clear_text(text, treshold=2):\n",
    "    text = regex.sub(\" \", text.lower()) # remove punctuation\n",
    "    text = re.sub(\"\\s\\s+\" , \" \", text) # remove multiple spacas\n",
    "    for k, v in negatives.items():\n",
    "        text = text.replace(k, v)\n",
    "    return text\n",
    "\n",
    "def rmsle(h, y): \n",
    "    \"\"\"\n",
    "    Compute the Root Mean Squared Log Error for hypothesis h and targets y\n",
    "\n",
    "    Args:\n",
    "        h - numpy array containing predictions with shape (n_samples, n_targets)\n",
    "        y - numpy array containing targets with shape (n_samples, n_targets)\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.square(np.log(h + 1) - np.log(y + 1)).mean())\n",
    "\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle, greater_is_better=False)\n",
    "\n",
    "def rmse_my(h, y): \n",
    "    \"\"\"\n",
    "    Compute the Root Mean Squared Log Error for hypothesis h and targets y\n",
    "\n",
    "    Args:\n",
    "        h - numpy array containing predictions with shape (n_samples, n_targets)\n",
    "        y - numpy array containing targets with shape (n_samples, n_targets)\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.square(h - y).mean())\n",
    "\n",
    "\n",
    "rmse_my_scorer = make_scorer(rmse_my, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/numpy/lib/arraysetops.py:463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "count_train = 1482535\n",
    "sample_subm = pd.DataFrame({'test_id':np.arange(693359), 'price':0}, columns=['test_id', 'price'])\n",
    "\n",
    "#defite target, log target and remove it from train data\n",
    "y_target = pd.read_csv('data/train.tsv', sep='\\t', index_col=0, usecols=['train_id', 'price']).price.values\n",
    "y_target_log = np.log1p(y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([pd.read_csv('data/train.tsv', sep='\\t', index_col=0).drop(['price'], axis=1), pd.read_csv('data/test.tsv', sep='\\t', index_col=0)])\n",
    "\n",
    "print('size of all_data and data_sample dataset: ', all_data.shape)\n",
    "\n",
    "print_memory()\n",
    "print('Data load')\n",
    "\n",
    "# # Preprosessing data\n",
    "\n",
    "# ### Remove NA\n",
    "# remove NA in item_description - 4 rows\n",
    "all_data['item_description'] = all_data['item_description'].fillna(value='No description yet')\n",
    "\n",
    "# fill NA in brand_name and category_name by 'missing'\n",
    "all_data[['name', 'category_name', 'brand_name']] = all_data[['name', 'category_name', 'brand_name']].fillna(value='missing', axis=1)\n",
    "\n",
    "print_memory()\n",
    "print('NA removed.')\n",
    "\n",
    "# ### Preprocess categorical features\n",
    "\n",
    "# create 3 categorical variables from category_name\n",
    "\n",
    "\n",
    "\n",
    "all_data['category'], all_data['sub_cat1'], all_data['sub_cat2'] = zip(*all_data['category_name'].apply(category_split))\n",
    "all_data.drop(['category_name'], axis=1, inplace=True)\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "all_data['brand_name'] = label_enc.fit_transform(all_data[['brand_name']])\n",
    "all_data['category'] = label_enc.fit_transform(all_data[['category']])\n",
    "all_data['sub_cat1'] = label_enc.fit_transform(all_data[['sub_cat1']])\n",
    "all_data['sub_cat2'] = label_enc.fit_transform(all_data[['sub_cat2']])\n",
    "\n",
    "print_memory()\n",
    "print('categorical variables OK!')\n",
    "\n",
    "\n",
    "# ### Preprocess text features\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_data['item_description'] = all_data.item_description.apply(clear_text)\n",
    "all_data['name'] = all_data.name.apply(clear_text)\n",
    "\n",
    "print_memory()\n",
    "print('data clear!')\n",
    "\n",
    "\n",
    "all_data['word_count_desc'] = all_data.item_description.apply(len_text)\n",
    "all_data['word_count_name'] = all_data.name.apply(len_text)\n",
    "\n",
    "gc.collect()\n",
    "print_memory()\n",
    "print('text feature ok!')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open('X_numeric.pickle', 'wb') as f:\n",
    "    pickle.dump(all_data[['item_condition_id', 'shipping', 'word_count_desc', 'word_count_name',\n",
    "                      'brand_name', 'category', 'sub_cat1', 'sub_cat2']], f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('data_description.pickle', 'wb') as f:\n",
    "    pickle.dump(all_data['item_description'], f, pickle.HIGHEST_PROTOCOL)   \n",
    "    \n",
    "with open('data_name.pickle', 'wb') as f:\n",
    "    pickle.dump(all_data['name'], f, pickle.HIGHEST_PROTOCOL)   \n",
    "\n",
    "del all_data\n",
    "gc.collect()\n",
    "print_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description tf-idf ok!\n",
      "used: 10.044845581054688\n",
      "all tf-idf ok!\n"
     ]
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer(min_df=0.0005, ngram_range=(1, 3), tokenizer=tokenize_text)\n",
    "\n",
    "with open('data_description.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    X_description = tf_idf.fit_transform(pickle.load(f))\n",
    "    print('description tf-idf ok!')\n",
    "\n",
    "print_memory()\n",
    "\n",
    "# tsvd_desc = TruncatedSVD(n_components=200)\n",
    "# X_description_svd = tsvd_desc.fit_transform(X_description)\n",
    "# print('TruncatedSVD description OK!')\n",
    "\n",
    "# del X_description\n",
    "# gc.collect()\n",
    "# print_memory()\n",
    "\n",
    "with open('data_name.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    X_name = tf_idf.fit_transform(pickle.load(f))\n",
    "    print('all tf-idf ok!')\n",
    "\n",
    "# tsvd_name = TruncatedSVD(n_components=30)\n",
    "# X_name_svd = tsvd_name.fit_transform(X_name)\n",
    "\n",
    "# print('TruncatedSVD all OK!')\n",
    "# del X_name\n",
    "# gc.collect()\n",
    "\n",
    "\n",
    "with open('X_numeric.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    X_numeric = MinMaxScaler().fit_transform(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of finish train and test dataset:  (1482535, 7033) (693359, 7033)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "train = hstack((X_description[:count_train,], X_name[:count_train,], X_numeric[:count_train,])).tocsr()\n",
    "test = hstack((X_description[count_train:,], X_name[count_train:,], X_numeric[count_train:,])).tocsr()\n",
    "\n",
    "print('size of finish train and test dataset: ', train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1260154, 7033) (222381, 7033) 1260154 222381\n"
     ]
    }
   ],
   "source": [
    "train_X, valid_X, train_y, valid_y = train_test_split(train, y_target_log, random_state=42, test_size=0.15)\n",
    "print(train_X.shape, valid_X.shape, len(train_y), len(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  2.1min remaining:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear CV score: -0.545692403092\n",
      "score test: 0.547312447432\n"
     ]
    }
   ],
   "source": [
    "# del X_description_svd\n",
    "# del X_name_svd\n",
    "# del X_numeric\n",
    "# gc.collect()\n",
    "# print_memory()\n",
    "\n",
    "# print('size of finish train and test dataset: ', train.shape, test.shape)\n",
    "\n",
    "#train_X, valid_X, train_y, valid_y = train_test_split(data_ok, y_target_log, random_state=42, test_size=0.05)\n",
    "\n",
    "\n",
    "param_grid_linear = {'normalize':[True]}\n",
    "cv_linear = GridSearchCV(LinearRegression(), param_grid_linear, scoring=rmse_my_scorer, cv=5, n_jobs=-1, verbose=1)\n",
    "cv_linear.fit(train_X, train_y)\n",
    "\n",
    "print('linear CV score:', cv_linear.best_score_)\n",
    "\n",
    "preds_linear = cv_linear.predict(valid_X)\n",
    "\n",
    "print('score test:', rmse_my(preds_linear, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score test: 0.547312446604\n"
     ]
    }
   ],
   "source": [
    "print('score test:', rmse_my(preds_linear, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description tf-idf ok!\n",
      "used: 8.472480773925781\n",
      "TruncatedSVD description OK!\n",
      "used: 11.380382537841797\n",
      "all tf-idf ok!\n",
      "TruncatedSVD all OK!\n",
      "size of finish train and test dataset:  (1482535, 238) (693359, 238)\n",
      "used: 6.52081298828125\n",
      "size of finish train and test dataset:  (1482535, 238) (693359, 238)\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear CV score: -0.415891098339\n"
     ]
    }
   ],
   "source": [
    "#preds_linear = cv_linear.best_estimator_.predict(test)\n",
    "sample_subm.price = np.expm1(cv_linear.best_estimator_.predict(test))\n",
    "sample_subm.to_csv(\"submission_linear_CV.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear CV score: -0.422297011147 for 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear CV score: -0.415576887713\n",
      "score test: 0.417793518429\n"
     ]
    }
   ],
   "source": [
    "param_grid_linear = {'normalize':[True]}\n",
    "cv_linear = GridSearchCV(LinearRegression(), param_grid_linear, scoring='neg_mean_squared_error', cv=5, n_jobs=-1, verbose=1)\n",
    "cv_linear.fit(train_X, train_y)\n",
    "\n",
    "print('linear CV score:', cv_linear.best_score_)\n",
    "\n",
    "#preds_linear = cv_linear.best_estimator_.predict(test)\n",
    "print('score test:', mean_squared_error(cv_linear.best_estimator_.predict(valid_X), valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's rmse: 0.517998\tvalid_1's rmse: 0.524789\n",
      "[1000]\ttraining's rmse: 0.497909\tvalid_1's rmse: 0.509423\n",
      "[1500]\ttraining's rmse: 0.486349\tvalid_1's rmse: 0.501498\n",
      "[2000]\ttraining's rmse: 0.47864\tvalid_1's rmse: 0.497125\n",
      "[2500]\ttraining's rmse: 0.47132\tvalid_1's rmse: 0.492829\n",
      "[3000]\ttraining's rmse: 0.465945\tvalid_1's rmse: 0.490404\n",
      "[3500]\ttraining's rmse: 0.460989\tvalid_1's rmse: 0.488338\n",
      "[4000]\ttraining's rmse: 0.456488\tvalid_1's rmse: 0.486767\n",
      "[4500]\ttraining's rmse: 0.452069\tvalid_1's rmse: 0.485054\n",
      "Early stopping, best iteration is:\n",
      "[4563]\ttraining's rmse: 0.451499\tvalid_1's rmse: 0.484902\n",
      "score test: 0.484901830891\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "d_train = lgb.Dataset(train_X, label=train_y)\n",
    "d_valid = lgb.Dataset(valid_X, label=valid_y)\n",
    "watchlist = [d_train, d_valid]\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.5,\n",
    "    'application': 'regression',\n",
    "    'max_depth': 3,\n",
    "    'num_leaves': 60,\n",
    "    'verbosity': -1,\n",
    "    'metric': 'RMSE',\n",
    "    'data_random_seed': 1,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "params2 = {\n",
    "    'learning_rate': 1,\n",
    "    'application': 'regression',\n",
    "    'max_depth': 3,\n",
    "    'num_leaves': 140,\n",
    "    'verbosity': -1,\n",
    "    'metric': 'RMSE',\n",
    "    'data_random_seed': 2,\n",
    "    'bagging_fraction': 1,\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "model = lgb.train(params, train_set=d_train, num_boost_round=8000, valid_sets=watchlist, \\\n",
    "                    early_stopping_rounds=50, verbose_eval=500) \n",
    "predsL = model.predict(valid_X)\n",
    "\n",
    "print('score test:', rmse_my(predsL, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha= 0.0  score test: 0.547312446604\n",
      "alpha= 0.0204081632653  score test: 0.544871788463\n",
      "alpha= 0.0408163265306  score test: 0.54247203276\n",
      "alpha= 0.0612244897959  score test: 0.540113724692\n",
      "alpha= 0.0816326530612  score test: 0.537797409519\n",
      "alpha= 0.102040816327  score test: 0.535523632138\n",
      "alpha= 0.122448979592  score test: 0.533292936651\n",
      "alpha= 0.142857142857  score test: 0.531105865902\n",
      "alpha= 0.163265306122  score test: 0.528962961008\n",
      "alpha= 0.183673469388  score test: 0.526864760875\n",
      "alpha= 0.204081632653  score test: 0.524811801691\n",
      "alpha= 0.224489795918  score test: 0.522804616417\n",
      "alpha= 0.244897959184  score test: 0.520843734251\n",
      "alpha= 0.265306122449  score test: 0.518929680092\n",
      "alpha= 0.285714285714  score test: 0.517062973982\n",
      "alpha= 0.30612244898  score test: 0.515244130539\n",
      "alpha= 0.326530612245  score test: 0.513473658386\n",
      "alpha= 0.34693877551  score test: 0.511752059563\n",
      "alpha= 0.367346938776  score test: 0.510079828937\n",
      "alpha= 0.387755102041  score test: 0.508457453598\n",
      "alpha= 0.408163265306  score test: 0.506885412258\n",
      "alpha= 0.428571428571  score test: 0.505364174641\n",
      "alpha= 0.448979591837  score test: 0.50389420087\n",
      "alpha= 0.469387755102  score test: 0.502475940857\n",
      "alpha= 0.489795918367  score test: 0.50110983369\n",
      "alpha= 0.510204081633  score test: 0.499796307019\n",
      "alpha= 0.530612244898  score test: 0.498535776459\n",
      "alpha= 0.551020408163  score test: 0.497328644981\n",
      "alpha= 0.571428571429  score test: 0.496175302326\n",
      "alpha= 0.591836734694  score test: 0.495076124416\n",
      "alpha= 0.612244897959  score test: 0.494031472788\n",
      "alpha= 0.632653061224  score test: 0.493041694032\n",
      "alpha= 0.65306122449  score test: 0.492107119245\n",
      "alpha= 0.673469387755  score test: 0.49122806351\n",
      "alpha= 0.69387755102  score test: 0.490404825382\n",
      "alpha= 0.714285714286  score test: 0.489637686403\n",
      "alpha= 0.734693877551  score test: 0.488926910635\n",
      "alpha= 0.755102040816  score test: 0.488272744222\n",
      "alpha= 0.775510204082  score test: 0.487675414971\n",
      "alpha= 0.795918367347  score test: 0.487135131965\n",
      "alpha= 0.816326530612  score test: 0.486652085201\n",
      "alpha= 0.836734693878  score test: 0.486226445267\n",
      "alpha= 0.857142857143  score test: 0.485858363037\n",
      "alpha= 0.877551020408  score test: 0.485547969411\n",
      "alpha= 0.897959183673  score test: 0.485295375081\n",
      "alpha= 0.918367346939  score test: 0.485100670336\n",
      "alpha= 0.938775510204  score test: 0.484963924902\n",
      "alpha= 0.959183673469  score test: 0.484885187814\n",
      "alpha= 0.979591836735  score test: 0.484864487333\n",
      "alpha= 1.0  score test: 0.484901830891\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.5\n",
    "for alpha in np.linspace(0, 1, 50):\n",
    "    print('alpha=', alpha, ' score test:', rmse_my(predsL * alpha + (1 - alpha) * preds_linear, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score test: 0.547315646056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge(alpha=.05, copy_X=True, fit_intercept=True, max_iter=100,\n",
    "      normalize=False, random_state=101, solver='auto', tol=0.001)\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "preds_ridge = model.predict(valid_X)\n",
    "\n",
    "print('score test:', rmse_my(preds_ridge, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1260154, 7033) (222381, 7033) 1260154 222381\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's rmse: 0.514086\tvalid_1's rmse: 0.525975\n",
      "[1000]\ttraining's rmse: 0.492521\tvalid_1's rmse: 0.511341\n",
      "[1500]\ttraining's rmse: 0.480879\tvalid_1's rmse: 0.506133\n",
      "Early stopping, best iteration is:\n",
      "[1780]\ttraining's rmse: 0.474929\tvalid_1's rmse: 0.503866\n",
      "score test: 0.503866340833\n"
     ]
    }
   ],
   "source": [
    "#train_X, valid_X, train_y, valid_y = train_test_split(train, y_target_log, random_state=101, test_size=0.15)\n",
    "print(train_X.shape, valid_X.shape, len(train_y), len(valid_y))\n",
    "\n",
    "d_train = lgb.Dataset(train_X, label=train_y)\n",
    "d_valid = lgb.Dataset(valid_X, label=valid_y)\n",
    "watchlist = [d_train, d_valid]\n",
    "model = lgb.train(params2, train_set=d_train, num_boost_round=8000, valid_sets=watchlist, \\\n",
    "                    early_stopping_rounds=50, verbose_eval=500) \n",
    "predsL2 = model.predict(valid_X)\n",
    "\n",
    "print('score test:', rmse_my(predsL2, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha= 0.0  score test: 0.503866340833\n",
      "alpha= 0.0204081632653  score test: 0.502681790929\n",
      "alpha= 0.0408163265306  score test: 0.501528075705\n",
      "alpha= 0.0612244897959  score test: 0.500405408433\n",
      "alpha= 0.0816326530612  score test: 0.499313998541\n",
      "alpha= 0.102040816327  score test: 0.498254051434\n",
      "alpha= 0.122448979592  score test: 0.497225768321\n",
      "alpha= 0.142857142857  score test: 0.496229346044\n",
      "alpha= 0.163265306122  score test: 0.495264976905\n",
      "alpha= 0.183673469388  score test: 0.494332848497\n",
      "alpha= 0.204081632653  score test: 0.493433143535\n",
      "alpha= 0.224489795918  score test: 0.492566039689\n",
      "alpha= 0.244897959184  score test: 0.491731709423\n",
      "alpha= 0.265306122449  score test: 0.490930319832\n",
      "alpha= 0.285714285714  score test: 0.490162032484\n",
      "alpha= 0.30612244898  score test: 0.489427003269\n",
      "alpha= 0.326530612245  score test: 0.488725382244\n",
      "alpha= 0.34693877551  score test: 0.48805731349\n",
      "alpha= 0.367346938776  score test: 0.487422934969\n",
      "alpha= 0.387755102041  score test: 0.486822378385\n",
      "alpha= 0.408163265306  score test: 0.486255769057\n",
      "alpha= 0.428571428571  score test: 0.485723225784\n",
      "alpha= 0.448979591837  score test: 0.485224860732\n",
      "alpha= 0.469387755102  score test: 0.484760779312\n",
      "alpha= 0.489795918367  score test: 0.484331080075\n",
      "alpha= 0.510204081633  score test: 0.483935854608\n",
      "alpha= 0.530612244898  score test: 0.483575187437\n",
      "alpha= 0.551020408163  score test: 0.483249155938\n",
      "alpha= 0.571428571429  score test: 0.482957830256\n",
      "alpha= 0.591836734694  score test: 0.48270127323\n",
      "alpha= 0.612244897959  score test: 0.482479540323\n",
      "alpha= 0.632653061224  score test: 0.482292679567\n",
      "alpha= 0.65306122449  score test: 0.482140731508\n",
      "alpha= 0.673469387755  score test: 0.482023729161\n",
      "alpha= 0.69387755102  score test: 0.481941697979\n",
      "alpha= 0.714285714286  score test: 0.48189465582\n",
      "alpha= 0.734693877551  score test: 0.481882612932\n",
      "alpha= 0.755102040816  score test: 0.481905571938\n",
      "alpha= 0.775510204082  score test: 0.481963527837\n",
      "alpha= 0.795918367347  score test: 0.482056468005\n",
      "alpha= 0.816326530612  score test: 0.482184372214\n",
      "alpha= 0.836734693878  score test: 0.482347212649\n",
      "alpha= 0.857142857143  score test: 0.48254495394\n",
      "alpha= 0.877551020408  score test: 0.482777553204\n",
      "alpha= 0.897959183673  score test: 0.483044960084\n",
      "alpha= 0.918367346939  score test: 0.48334711681\n",
      "alpha= 0.938775510204  score test: 0.483683958257\n",
      "alpha= 0.959183673469  score test: 0.484055412017\n",
      "alpha= 0.979591836735  score test: 0.484461398475\n",
      "alpha= 1.0  score test: 0.484901830891\n"
     ]
    }
   ],
   "source": [
    "for alpha in np.linspace(0, 1, 50):\n",
    "    print('alpha=', alpha, ' score test:', rmse_my(predsL * alpha + (1 - alpha) * predsL2, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score -0.509 params {'colsample_bytree': '0.549', 'learning_rate': '0.624', 'num_leaves': 62, 'n_estimators': 75}\n",
      "Score -0.542 params {'colsample_bytree': '0.904', 'learning_rate': '0.608', 'num_leaves': 20, 'n_estimators': 50}\n",
      "Score -0.483 params {'colsample_bytree': '0.852', 'learning_rate': '0.349', 'num_leaves': 74, 'n_estimators': 450}\n",
      "Score -0.515 params {'colsample_bytree': '0.370', 'learning_rate': '0.820', 'num_leaves': 102, 'n_estimators': 475}\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    params = {\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'learning_rate': '{:.3f}'.format(params['learning_rate']),\n",
    "    }\n",
    "    \n",
    "    clf = lgb.LGBMRegressor(\n",
    "        #n_estimators=500,\n",
    "        #learning_rate=0.01,\n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    score = cross_val_score(clf, train, y_target_log, scoring=rmse_my_scorer, cv=3).mean()\n",
    "    print(\"Score {:.3f} params {}\".format(score, params))\n",
    "    return score\n",
    "\n",
    "space = {\n",
    "    'num_leaves': hp.quniform('num_leaves', 8, 128, 2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 500, 25),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.1, 1.0)\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10,\n",
    "           verbose=1)\n",
    "\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 21.7min finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score test: 0.632517326612\n"
     ]
    }
   ],
   "source": [
    "cls_rf = RandomForestRegressor(n_estimators=50, max_depth=10, n_jobs=-1, criterion='mse', verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 29.48, NNZs: 7033, Bias: 2.987773, T: 1260154, Avg. loss: 0.489053\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 29.97, NNZs: 7033, Bias: 3.023569, T: 2520308, Avg. loss: 0.487582\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.35, NNZs: 7033, Bias: 2.952076, T: 3780462, Avg. loss: 0.486805\n",
      "Total training time: 1.84 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.11, NNZs: 7033, Bias: 2.970759, T: 5040616, Avg. loss: 0.487350\n",
      "Total training time: 2.48 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30.26, NNZs: 7033, Bias: 3.003744, T: 6300770, Avg. loss: 0.487546\n",
      "Total training time: 3.09 seconds.\n",
      "score test: 0.685491348431\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "\n",
    "cls_pass = PassiveAggressiveRegressor(verbose=1)\n",
    "cls_pass.fit(train_X, train_y)\n",
    "\n",
    "preds_pass = cls_pass.predict(valid_X)\n",
    "print('score test:', rmse_my(preds_pass, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
