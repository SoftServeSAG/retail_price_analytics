{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "tcurrent   = start_time\n",
    "\n",
    "#np.random.seed(1313)  # v01\n",
    "np.random.seed(27)  # v11\n",
    "\n",
    "NUM_BRANDS = 4100\n",
    "NUM_CATEGORIES = 1000\n",
    "NAME_MIN_DF = 10\n",
    "MAX_FEATURES_ITEM_DESCRIPTION = 51000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_inplace(dataset):\n",
    "    dataset['category_name'].fillna(value='missing', inplace=True)\n",
    "    dataset['brand_name'].fillna(value='missing', inplace=True)\n",
    "    dataset['item_description'].fillna(value='missing', inplace=True)\n",
    "\n",
    "\n",
    "def cutting(dataset):\n",
    "    pop_brand = dataset['brand_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_BRANDS]\n",
    "    dataset.loc[~dataset['brand_name'].isin(pop_brand), 'brand_name'] = 'missing'\n",
    "    pop_category = dataset['category_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_BRANDS]\n",
    "    dataset.loc[~dataset['category_name'].isin(pop_category), 'category_name'] = 'missing'\n",
    "\n",
    "\n",
    "def to_categorical(dataset):\n",
    "    dataset['category_name'] = dataset['category_name'].astype('category')\n",
    "    dataset['brand_name'] = dataset['brand_name'].astype('category')\n",
    "    dataset['item_condition_id'] = dataset['item_condition_id'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.100717306137085] Finished to load data\n",
      "Train shape:  (1482535, 8)\n",
      "Test shape:  (693359, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train = pd.read_table('data/train.tsv', engine='c')\n",
    "test = pd.read_table('data/test.tsv', engine='c')\n",
    "print('[{}] Finished to load data'.format(time.time() - start_time))\n",
    "print('Train shape: ', train.shape)\n",
    "print('Test shape: ', test.shape)\n",
    "\n",
    "nrow_train = train.shape[0]\n",
    "y = np.log1p(train[\"price\"])\n",
    "merge = pd.concat([train, test])\n",
    "submission = test[['test_id']]\n",
    "\n",
    "del train\n",
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.613053321838379] Finished to handle missing\n",
      "[6.359637975692749] Finished to cut\n",
      "[6.7107744216918945] Finished to convert categorical\n",
      "[16.646504878997803] Finished count vectorize `name`\n",
      "[25.399235486984253] Finished count vectorize `category_name`\n"
     ]
    }
   ],
   "source": [
    "handle_missing_inplace(merge)\n",
    "print('[{}] Finished to handle missing'.format(time.time() - start_time))\n",
    "\n",
    "cutting(merge)\n",
    "print('[{}] Finished to cut'.format(time.time() - start_time))\n",
    "\n",
    "to_categorical(merge)\n",
    "print('[{}] Finished to convert categorical'.format(time.time() - start_time))\n",
    "\n",
    "cv = CountVectorizer(min_df=NAME_MIN_DF)\n",
    "X_name = cv.fit_transform(merge['name'])\n",
    "print('[{}] Finished count vectorize `name`'.format(time.time() - start_time))\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X_category = cv.fit_transform(merge['category_name'])\n",
    "print('[{}] Finished count vectorize `category_name`'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[216.61707043647766] Finished TFIDF vectorize `item_description`\n",
      "[224.04442834854126] Finished label binarize `brand_name`\n",
      "[226.82568788528442] Finished to get dummies on `item_condition_id` and `shipping`\n",
      "[229.50633549690247] Finished to create sparse merge\n"
     ]
    }
   ],
   "source": [
    "tv = TfidfVectorizer(max_features=MAX_FEATURES_ITEM_DESCRIPTION,\n",
    "                     ngram_range=(1, 3),\n",
    "                     stop_words='english')\n",
    "X_description = tv.fit_transform(merge['item_description'])\n",
    "print('[{}] Finished TFIDF vectorize `item_description`'.format(time.time() - start_time))\n",
    "\n",
    "lb = LabelBinarizer(sparse_output=True)\n",
    "X_brand = lb.fit_transform(merge['brand_name'])\n",
    "print('[{}] Finished label binarize `brand_name`'.format(time.time() - start_time))\n",
    "\n",
    "X_dummies = csr_matrix(pd.get_dummies(merge[['item_condition_id', 'shipping']],\n",
    "                                      sparse=True).values)\n",
    "print('[{}] Finished to get dummies on `item_condition_id` and `shipping`'.format(time.time() - start_time))\n",
    "\n",
    "sparse_merge = hstack((X_dummies, X_description, X_brand, X_category, X_name)).tocsr()\n",
    "print('[{}] Finished to create sparse merge'.format(time.time() - start_time))\n",
    "\n",
    "X = sparse_merge[:nrow_train]\n",
    "X_test = sparse_merge[nrow_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2175894x4101 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2175894 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[514.9087607860565] Finished to train ridge sag\n",
      "[514.9510307312012] Finished to predict ridge sag\n"
     ]
    }
   ],
   "source": [
    "# def rmsle(y, y0):\n",
    "#     assert len(y) == len(y0)\n",
    "#     return np.sqrt(np.mean(np.power(np.log1p(y)-np.log1p(y0), 2)))\n",
    "\n",
    "model = Ridge(solver=\"sag\", fit_intercept=True, random_state=205, alpha=3)\n",
    "model.fit(X, y)\n",
    "print('[{}] Finished to train ridge sag'.format(time.time() - start_time))\n",
    "predsR = model.predict(X=X_test)\n",
    "print('[{}] Finished to predict ridge sag'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/SSD/dzikr/env_python_3/env_p_3/lib/python3.4/site-packages/sklearn/linear_model/ridge.py:319: UserWarning: In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "  warnings.warn(\"In Ridge, only 'sag' solver can currently fit the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[586.71910572052] Finished to train ridge lsqrt\n",
      "[586.7622191905975] Finished to predict ridge lsqrt\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(solver=\"lsqr\", fit_intercept=True, random_state=145, alpha = 3)\n",
    "model.fit(X, y)\n",
    "print('[{}] Finished to train ridge lsqrt'.format(time.time() - start_time))\n",
    "predsR2 = model.predict(X=X_test)\n",
    "print('[{}] Finished to predict ridge lsqrt'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's rmse: 0.486392\tvalid_1's rmse: 0.493768\n",
      "[1000]\ttraining's rmse: 0.466157\tvalid_1's rmse: 0.47766\n",
      "[1500]\ttraining's rmse: 0.455084\tvalid_1's rmse: 0.470909\n",
      "[2000]\ttraining's rmse: 0.447432\tvalid_1's rmse: 0.46709\n",
      "Early stopping, best iteration is:\n",
      "[2235]\ttraining's rmse: 0.443993\tvalid_1's rmse: 0.465443\n",
      "[2507.033341407776] Finished to predict lgb 1\n"
     ]
    }
   ],
   "source": [
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, random_state=666, test_size=0.0338) \n",
    "d_train = lgb.Dataset(train_X, label=train_y)#, max_bin=8192)\n",
    "d_valid = lgb.Dataset(valid_X, label=valid_y)#, max_bin=8192)\n",
    "watchlist = [d_train, d_valid]\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.78,\n",
    "    'application': 'regression',\n",
    "    'max_depth': 3,\n",
    "    'num_leaves': 99,\n",
    "    'verbosity': -1,\n",
    "    'metric': 'RMSE',\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "params2 = {\n",
    "    'learning_rate': 0.88,\n",
    "    'application': 'regression',\n",
    "    'max_depth': 3,\n",
    "    'num_leaves': 110,\n",
    "    'verbosity': -1,\n",
    "    'metric': 'RMSE',\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "model = lgb.train(params, train_set=d_train, num_boost_round=7500, valid_sets=watchlist, \\\n",
    "early_stopping_rounds=50, verbose_eval=500) \n",
    "predsL = model.predict(X_test)\n",
    "\n",
    "print('[{}] Finished to predict lgb 1'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's rmse: 0.483399\tvalid_1's rmse: 0.490801\n",
      "[1000]\ttraining's rmse: 0.464132\tvalid_1's rmse: 0.476371\n",
      "[1500]\ttraining's rmse: 0.453475\tvalid_1's rmse: 0.470414\n",
      "[2000]\ttraining's rmse: 0.44529\tvalid_1's rmse: 0.466469\n",
      "[2500]\ttraining's rmse: 0.439088\tvalid_1's rmse: 0.464459\n",
      "Early stopping, best iteration is:\n",
      "[2677]\ttraining's rmse: 0.437254\tvalid_1's rmse: 0.464101\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(params2, train_set=d_train, num_boost_round=7500, valid_sets=watchlist, \\\n",
    "early_stopping_rounds=50, verbose_eval=500) \n",
    "predsL = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's rmse: 0.485637\tvalid_1's rmse: 0.491541\n",
      "[1000]\ttraining's rmse: 0.465196\tvalid_1's rmse: 0.476124\n",
      "[1500]\ttraining's rmse: 0.454091\tvalid_1's rmse: 0.469819\n",
      "[2000]\ttraining's rmse: 0.446163\tvalid_1's rmse: 0.466077\n",
      "[2500]\ttraining's rmse: 0.44003\tvalid_1's rmse: 0.464134\n",
      "[3000]\ttraining's rmse: 0.434971\tvalid_1's rmse: 0.463006\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.434971\tvalid_1's rmse: 0.463006\n",
      "[12445.733229637146] Finished to predict lgb 2\n"
     ]
    }
   ],
   "source": [
    "train_X2, valid_X2, train_y2, valid_y2 = train_test_split(X, y, test_size = 0.1, random_state = 101) \n",
    "d_train2 = lgb.Dataset(train_X2, label=train_y2)#, max_bin=8192)\n",
    "d_valid2 = lgb.Dataset(valid_X2, label=valid_y2)#, max_bin=8192)\n",
    "watchlist2 = [d_train2, d_valid2]\n",
    "\n",
    "model = lgb.train(params2, train_set=d_train2, num_boost_round=3000, valid_sets=watchlist2, \\\n",
    "early_stopping_rounds=50, verbose_eval=500) \n",
    "predsL2 = model.predict(X_test)\n",
    "\n",
    "print('[{}] Finished to predict lgb 2'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predsR2*0.20 + predsR*0.20 + predsL*0.40 + predsL2*0.20\n",
    "submission['price'] = np.expm1(preds)\n",
    "submission.to_csv(\"submission_lgbm_ridge_8 20 20 40 20 v11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predsR2*0.19 + predsR*0.19 + predsL*0.44 + predsL2*0.18\n",
    "submission['price'] = np.expm1(preds)\n",
    "submission.to_csv(\"submission_lgbm_ridge_8 19 19 44 18 v1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predsR2*0.18 + predsR*0.18 + predsL*0.45 + predsL2*0.19\n",
    "submission['price'] = np.expm1(preds)\n",
    "submission.to_csv(\"submission_lgbm_ridge_8 18 18 45 19 v11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predsR2*0.17 + predsR*0.17 + predsL*0.46 + predsL2*0.20\n",
    "submission['price'] = np.expm1(preds)\n",
    "submission.to_csv(\"submission_lgbm_ridge_8 17 17 46 20 v11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predsR2*0.16 + predsR*0.16 + predsL*0.48 + predsL2*0.20\n",
    "submission['price'] = np.expm1(preds)\n",
    "submission.to_csv(\"submission_lgbm_ridge_8 16 16 48 20 v11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm=(time.time() - start_time)/60\n",
    "print (\"Total time %s min\" % nm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
